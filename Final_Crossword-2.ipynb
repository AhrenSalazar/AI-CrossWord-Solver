{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhrenSalazar/AI-CrossWord-Solver/blob/main/Final_Crossword-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio and scikit-learn\n",
        "!pip install -q gradio\n",
        "!pip install -q scikit-learn\n"
      ],
      "metadata": {
        "id": "blGB0mNTovlv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm TF version and TextVectorization availability\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"TextVectorization loaded OK\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvPlRLo-s_e2",
        "outputId": "422be615-847b-4549-d446-fc2c7bd2f5f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "TextVectorization loaded OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUkfjFCDpVPe",
        "outputId": "f92599d7-0992-4963-b6e8-6e55ec555b06"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, math, pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Attention, Concatenate, AdditiveAttention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the base directory for saving model artifacts\n",
        "BASE_DIR = '/content/drive/MyDrive/crossword_model'\n",
        "# Create the directory if it doesn't already exist\n",
        "os.makedirs(BASE_DIR, exist_ok=True)\n",
        "\n",
        "# Define the path to the CSV dataset (change if needed)\n",
        "CSV_PATH = '/content/drive/MyDrive/Colab Notebooks/nytcrosswords.csv'\n",
        "# Set the save directory for models and other files\n",
        "SAVE_DIR = BASE_DIR\n",
        "\n",
        "# --- Hyperparameters ---\n",
        "# Batch size for training\n",
        "BATCH_SIZE = 128\n",
        "# Number of training epochs\n",
        "EPOCHS = 8\n",
        "# Dimension of the encoder embedding layer\n",
        "ENC_EMB_DIM = 256\n",
        "# Dimension of the decoder embedding layer\n",
        "DEC_EMB_DIM = 256\n",
        "# Number of units in the encoder LSTM layer\n",
        "ENC_UNITS = 512\n",
        "# Number of units in the decoder LSTM layer\n",
        "DEC_UNITS = 512\n",
        "# Maximum number of tokens (word-level) for a clue sequence\n",
        "CLUE_SEQ_LEN = 40\n",
        "# Maximum characters allowed in an answer (excluding Start/End of Sequence tokens)\n",
        "ANS_MAX = 12\n",
        "# Full sequence length for answers, including SOS and EOS tokens\n",
        "ANS_SEQ_LEN = ANS_MAX + 2\n",
        "# Length of decoder inputs (SOS + up to ANS_MAX characters), equals ANS_MAX + 1\n",
        "DECODER_INPUT_LEN = ANS_SEQ_LEN - 1\n",
        "print(\"DECODER_INPUT_LEN:\", DECODER_INPUT_LEN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_jf04D2pewM",
        "outputId": "1f2d57ba-8c7f-4495-c8ec-14a758c8dabc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DECODER_INPUT_LEN: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(CSV_PATH, encoding='latin1')\n",
        "df = df.dropna(subset=[\"Word\",\"Clue\"])\n",
        "df['input_text'] = df['Clue'].astype(str).str.lower().str.strip()\n",
        "df['target_text'] = df['Word'].astype(str).str.upper().str.strip()\n",
        "\n",
        "# Filter very long answers or empty entries\n",
        "df = df[df['input_text'].str.len() > 0]\n",
        "df = df[df['target_text'].str.len() > 0]\n",
        "df = df[df['target_text'].str.len() <= ANS_MAX]  # keep answers of reasonable length\n",
        "\n",
        "print(\"Total rows after filtering:\", len(df))\n",
        "train_df, val_df = train_test_split(df[['input_text','target_text']], test_size=0.05, random_state=42)\n",
        "print(\"Train size:\", len(train_df), \"Val size:\", len(val_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pgVOsvVpl2J",
        "outputId": "911e6b59-34cf-4324-cd00-e363183957f1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows after filtering: 777503\n",
            "Train size: 738627 Val size: 38876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clue vectorizer: word-level tokens\n",
        "# Converts clue text into sequences of integer word IDs.\n",
        "clue_vectorizer = TextVectorization(\n",
        "    output_mode='int',  # Output integer indices for words\n",
        "    output_sequence_length=CLUE_SEQ_LEN,  # Pad/truncate sequences to this length\n",
        "    standardize='lower_and_strip_punctuation' # Convert text to lowercase and remove punctuation\n",
        ")\n",
        "clue_vectorizer.adapt(train_df['input_text'].values) # Learns the vocabulary from the training clues\n",
        "\n",
        "# Answer vectorizer: character-level with explicit vocabulary (special tokens first)\n",
        "# Converts answer characters into sequences of integer character IDs.\n",
        "chars = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'-.\")  # Define allowed characters\n",
        "ans_vocab = ['[UNK]','[SOS]','[EOS]'] + chars # Create the full vocabulary including special tokens\n",
        "answer_vectorizer = TextVectorization(\n",
        "    output_mode='int', # Output integer indices for characters\n",
        "    split='character', # Split input strings into individual characters\n",
        "    output_sequence_length=ANS_SEQ_LEN, # Pad/truncate sequences to this length\n",
        "    standardize=lambda s: tf.strings.strip(s) # Custom standardization: just strip whitespace\n",
        ")\n",
        "answer_vectorizer.set_vocabulary(ans_vocab) # Manually set the vocabulary to include special tokens and chars\n",
        "\n",
        "print(\"Clue vocab size:\", len(clue_vectorizer.get_vocabulary()))\n",
        "print(\"Answer vocab size:\", len(answer_vectorizer.get_vocabulary()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foRme2JAqdNO",
        "outputId": "e864eee7-db0f-4bc8-c964-3f1b6d0c4564"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clue vocab size: 86517\n",
            "Answer vocab size: 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# answer_vectorizer.get_vocabulary()\n",
        "\n",
        "# Create a dictionary mapping integer IDs to tokens (characters)\n",
        "# From the vocabulary of the answer_vectorizer.\n",
        "idx_to_token = {i: t for i, t in enumerate(answer_vectorizer.get_vocabulary())}\n",
        "# Maps the integer ID of each character back to its character string.\n",
        "\n",
        "# Create a dictionary mapping tokens (characters) to their integer IDs\n",
        "# This is the inverse of idx_to_token.\n",
        "token_to_idx = {t: i for i, t in idx_to_token.items()}\n",
        "\n",
        "# Define special token IDs for Start Of Sequence, End Of Sequence, and Unknown characters\n",
        "SOS = token_to_idx['[SOS]'] # Integer ID for the Start Of Sequence token\n",
        "EOS = token_to_idx['[EOS]'] # Integer ID for the End Of Sequence token\n",
        "UNK = token_to_idx['[UNK]'] # Integer ID for the Unknown token\n",
        "\n",
        "def answers_to_seq(arr):\n",
        "    \"\"\"\n",
        "    Convert array-like of uppercase answer strings to fixed-length int sequences:\n",
        "    Each sequence = [SOS] + chars + [EOS] then padded/truncated to ANS_SEQ_LEN.\n",
        "    Returns numpy array shape (N, ANS_SEQ_LEN)\n",
        "    \"\"\"\n",
        "    seqs = []\n",
        "    for s in arr:\n",
        "        # Convert answer to uppercase string and remove leading/trailing whitespace\n",
        "        s = str(s).strip().upper()\n",
        "        # Convert the answer string into a list of individual characters\n",
        "        chars_list = list(s)\n",
        "        # Construct the sequence: start with SOS, map each character to its ID (or UNK if not found),\n",
        "        # then append EOS.\n",
        "        seq = [SOS] + [token_to_idx.get(c, UNK) for c in chars_list] + [EOS]\n",
        "\n",
        "        # Pad or truncate the sequence to the predefined ANS_SEQ_LEN\n",
        "        if len(seq) < ANS_SEQ_LEN:\n",
        "            # If shorter, pad with zeros until it reaches ANS_SEQ_LEN\n",
        "            seq = seq + [0] * (ANS_SEQ_LEN - len(seq))\n",
        "        else:\n",
        "            # If longer, truncate to ANS_SEQ_LEN\n",
        "            seq = seq[:ANS_SEQ_LEN]\n",
        "        seqs.append(seq)\n",
        "    # Convert the list of integer sequences into a NumPy array with int32 data type\n",
        "    return np.array(seqs, dtype=np.int32)"
      ],
      "metadata": {
        "id": "9mT_MbT1ql-f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_dataset(df_in, batch=BATCH_SIZE, shuffle=True):\n",
        "    # Vectorize clues using the pre-trained clue_vectorizer\n",
        "    clues = clue_vectorizer(np.array(df_in['input_text'].astype(str)))\n",
        "\n",
        "    # Convert answer strings to integer sequences using answers_to_seq function\n",
        "    answers_seq = answers_to_seq(df_in['target_text'].astype(str).values)  # shape (N, ANS_SEQ_LEN)\n",
        "\n",
        "    # Prepare decoder input and target sequences\n",
        "    # Decoder input is the answer sequence shifted by one token to the left (starts with SOS, ends before EOS)\n",
        "    decoder_input = answers_seq[:, :-1]   # (batch, dec_len)\n",
        "    # Decoder target is the answer sequence shifted by one token to the right (starts after SOS, ends with EOS)\n",
        "    decoder_target = answers_seq[:, 1:]   # (batch, dec_len)\n",
        "\n",
        "    # Convert decoder target to a TensorFlow tensor with int32 dtype\n",
        "    # This removes any potential extra dimension if it was added implicitly and ensures correct dtype\n",
        "    decoder_target = tf.convert_to_tensor(decoder_target, dtype=tf.int32)\n",
        "\n",
        "    # Create a TensorFlow Dataset from the processed clues, decoder inputs, and decoder targets\n",
        "    # The dataset yields tuples of ((encoder_input, decoder_input), decoder_target)\n",
        "    ds = tf.data.Dataset.from_tensor_slices(((clues, decoder_input), decoder_target))\n",
        "\n",
        "    # Shuffle the dataset probably not total required though\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(20000)\n",
        "\n",
        "    # Batch the dataset and prefetch elements for performance optimization\n",
        "    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "# Create training and validation datasets\n",
        "train_ds = format_dataset(train_df, batch=BATCH_SIZE, shuffle=True)\n",
        "val_ds = format_dataset(val_df, batch=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(\"Train ds example batch shapes:\")\n",
        "# Take one batch from the training dataset and print the shapes of its components\n",
        "for (x,y), t in train_ds.take(1):\n",
        "    print(\"encoder_input:\", x.shape,\n",
        "          \"decoder_input:\", y.shape,\n",
        "          \"decoder_target:\", t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIiRaw1wqn8v",
        "outputId": "7c1867e1-0027-4952-fca3-414d5e3ba8c5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train ds example batch shapes:\n",
            "encoder_input: (128, 40) decoder_input: (128, 13) decoder_target: (128, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Redeclare ENC_UNITS and DEC_UNITS because kept running into a weird bug\n",
        "\n",
        "# Encoder and Decoder units are reset to ensure consistency if previous cells modified them.\n",
        "ENC_UNITS = 256\n",
        "DEC_UNITS = 256\n",
        "\n",
        "# --- Encoder Definition ---\n",
        "# Input layer for the encoder, expecting a sequence of clue token IDs\n",
        "encoder_inputs = Input(shape=(CLUE_SEQ_LEN,), dtype='int32', name='encoder_inputs')\n",
        "# Embedding layer for encoder inputs, converting token IDs to dense vectors\n",
        "enc_emb = Embedding(\n",
        "    input_dim=len(clue_vectorizer.get_vocabulary()), # Size of the vocabulary\n",
        "    output_dim=ENC_EMB_DIM,                          # Dimension of the embedding vectors\n",
        "    mask_zero=True,                                  # Enable masking for padded zeros\n",
        "    name='enc_emb'\n",
        ")(encoder_inputs)\n",
        "\n",
        "# Encoder LSTM layer: processes the embedded clue sequence\n",
        "# return_sequences=True to get hidden states for all time steps (for attention)\n",
        "# return_state=True to get final hidden and cell states (to initialize decoder)\n",
        "# use_cudnn=False to avoid cuDNN-related masking issues\n",
        "encoder_lstm = LSTM(ENC_UNITS, return_sequences=True, return_state=True, name='encoder_lstm', use_cudnn=False)\n",
        "enc_outputs, enc_state_h, enc_state_c = encoder_lstm(enc_emb)\n",
        "\n",
        "# --- Decoder Definition ---\n",
        "# Input layer for the decoder, expecting a sequence of answer character IDs (shifted)\n",
        "decoder_inputs = Input(shape=(DECODER_INPUT_LEN,), dtype='int32', name='decoder_inputs')\n",
        "# Embedding layer for decoder inputs, converting character IDs to dense vectors\n",
        "dec_emb = Embedding(\n",
        "    input_dim=len(answer_vectorizer.get_vocabulary()), # Size of the vocabulary\n",
        "    output_dim=DEC_EMB_DIM,                            # Dimension of the embedding vectors\n",
        "    mask_zero=True,                                    # Enable masking for padded zeros\n",
        "    name='dec_emb'\n",
        ")(decoder_inputs)\n",
        "\n",
        "# Decoder LSTM layer: processes the embedded answer sequence\n",
        "# return_sequences=True to get hidden states for all time steps (for attention)\n",
        "# Initial state is set from the encoder's final states (h and c)\n",
        "# use_cudnn=False to avoid cuDNN-related masking issues\n",
        "decoder_lstm = LSTM(DEC_UNITS, return_sequences=True, return_state=True, name='decoder_lstm', use_cudnn=False)\n",
        "dec_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[enc_state_h, enc_state_c])\n",
        "\n",
        "# --- Attention Mechanism ---\n",
        "# Additive Attention layer to compute context vectors\n",
        "attn = AdditiveAttention(name='attention_layer')\n",
        "\n",
        "# Explicitly expand the encoder mask to (batch, 1, clue_seq_len) for broadcasting compatibility\n",
        "# This is a specific fix for a known issue with AdditiveAttention and masking in TF 2.19\n",
        "expanded_enc_mask = tf.keras.ops.expand_dims(enc_emb._keras_mask, axis=1)\n",
        "\n",
        "# Calculate context vector: combines decoder outputs (query) and encoder outputs (value)\n",
        "# Masks are applied to ignore padded tokens during attention calculation\n",
        "context = attn(\n",
        "    [dec_outputs, enc_outputs],\n",
        "    mask=[dec_emb._keras_mask, expanded_enc_mask]   # Pass decoder and expanded encoder masks\n",
        ")\n",
        "\n",
        "# --- Output Layer ---\n",
        "# Concatenate the context vector with the decoder's hidden states\n",
        "concat = Concatenate(axis=-1, name='concat_layer')([context, dec_outputs])\n",
        "# Dense output layer predicts the probability distribution over the answer vocabulary\n",
        "decoder_dense = Dense(len(answer_vectorizer.get_vocabulary()), activation='softmax', name='decoder_dense')\n",
        "decoder_outputs = decoder_dense(concat)\n",
        "\n",
        "# --- Training Model Definition ---\n",
        "# Define the full training model: takes encoder and decoder inputs, outputs decoder predictions\n",
        "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "# Compile the model with Adam optimizer and sparse categorical crossentropy loss\n",
        "training_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")\n",
        "# Print a summary of the model architecture\n",
        "training_model.summary()"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "uIeEbM8fqrwd",
        "outputId": "893935e4-1ada-4543-b993-bb2c7a06d93b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ enc_emb (\u001b[38;5;33mEmbedding\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │ \u001b[38;5;34m22,148,352\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dec_emb (\u001b[38;5;33mEmbedding\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │     \u001b[38;5;34m11,264\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m525,312\u001b[0m │ enc_emb[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m525,312\u001b[0m │ dec_emb[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ expand_dims_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m40\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mExpandDims\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ not_equal_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ expand_dims_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concat_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ attention_layer[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m44\u001b[0m)    │     \u001b[38;5;34m22,572\u001b[0m │ concat_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ enc_emb (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">22,148,352</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dec_emb (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">11,264</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ enc_emb[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ dec_emb[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ expand_dims_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ExpandDims</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ not_equal_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ expand_dims_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concat_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">22,572</span> │ concat_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,233,068\u001b[0m (88.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,233,068</span> (88.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,233,068\u001b[0m (88.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,233,068</span> (88.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training!\n",
        "\n",
        "checkpoint_path = os.path.join(SAVE_DIR, 'best_weights.weights.h5')  # must end with .weights.h5\n",
        "checkpoint_cb = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
        "\n",
        "start = time.time()\n",
        "history = training_model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=[checkpoint_cb, reduce_lr])\n",
        "print(\"Training time (s):\", time.time() - start)\n",
        "\n",
        "# Save final weights\n",
        "training_model.save_weights(os.path.join(SAVE_DIR, 'final_weights.weights.h5'))\n",
        "print(\"Saved best weights to\", checkpoint_path)\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-Giw1Ncqx9S",
        "outputId": "eae730ef-702c-4113-aae3-0916f22accb0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m5771/5771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 29ms/step - loss: 1.9023 - sparse_categorical_accuracy: 0.2854 - val_loss: 1.4778 - val_sparse_categorical_accuracy: 0.3583 - learning_rate: 0.0010\n",
            "Epoch 2/8\n",
            "\u001b[1m5771/5771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 28ms/step - loss: 1.3618 - sparse_categorical_accuracy: 0.3942 - val_loss: 1.3228 - val_sparse_categorical_accuracy: 0.4041 - learning_rate: 0.0010\n",
            "Epoch 3/8\n",
            "\u001b[1m5771/5771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 28ms/step - loss: 1.1210 - sparse_categorical_accuracy: 0.4257 - val_loss: 1.2683 - val_sparse_categorical_accuracy: 0.3916 - learning_rate: 0.0010\n",
            "Epoch 4/8\n",
            "\u001b[1m5771/5771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 28ms/step - loss: 0.9628 - sparse_categorical_accuracy: 0.4340 - val_loss: 1.2535 - val_sparse_categorical_accuracy: 0.3622 - learning_rate: 0.0010\n",
            "Epoch 5/8\n",
            "\u001b[1m5771/5771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 27ms/step - loss: 0.8466 - sparse_categorical_accuracy: 0.4235 - val_loss: 1.2616 - val_sparse_categorical_accuracy: 0.3576 - learning_rate: 0.0010\n",
            "Epoch 6/8\n",
            "\u001b[1m5771/5771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 26ms/step - loss: 0.7578 - sparse_categorical_accuracy: 0.4221 - val_loss: 1.2859 - val_sparse_categorical_accuracy: 0.3555 - learning_rate: 0.0010\n",
            "Epoch 7/8\n",
            "\u001b[1m5771/5771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 27ms/step - loss: 0.6489 - sparse_categorical_accuracy: 0.4322 - val_loss: 1.3098 - val_sparse_categorical_accuracy: 0.3600 - learning_rate: 5.0000e-04\n",
            "Epoch 8/8\n",
            "\u001b[1m5771/5771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 27ms/step - loss: 0.5777 - sparse_categorical_accuracy: 0.4421 - val_loss: 1.3527 - val_sparse_categorical_accuracy: 0.3599 - learning_rate: 5.0000e-04\n",
            "Training time (s): 1309.635303735733\n",
            "Saved best weights to /content/drive/MyDrive/crossword_model/best_weights.weights.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving weights + vectors\n",
        "with open(os.path.join(SAVE_DIR, 'clue_vectorizer.pkl'), 'wb') as f:\n",
        "    pickle.dump(clue_vectorizer, f)\n",
        "with open(os.path.join(SAVE_DIR, 'answer_vectorizer.pkl'), 'wb') as f:\n",
        "    pickle.dump(answer_vectorizer, f)\n",
        "\n",
        "print(\"Saved vectorizers to\", SAVE_DIR)\n",
        "print(\"Best weights:\", checkpoint_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRXTJbsQq2H_",
        "outputId": "a5ec022b-76d3-49a4-a937-9ef70d5d3125"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved vectorizers to /content/drive/MyDrive/crossword_model\n",
            "Best weights: /content/drive/MyDrive/crossword_model/best_weights.weights.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/serialization_lib.py:390: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized:     standardize=lambda s: tf.strings.strip(s)\n",
            "\n",
            "  return {key: serialize_keras_object(value) for key, value in obj.items()}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rebuild training architecture\n",
        "# (redeclare inputs, layers variable names to allow layer lookup and reuse)\n",
        "\n",
        "# Encoder Definition (matching the training model for weight loading)\n",
        "encoder_inputs = Input(shape=(CLUE_SEQ_LEN,), dtype='int32', name='encoder_inputs')\n",
        "enc_emb = Embedding(input_dim=len(clue_vectorizer.get_vocabulary()), output_dim=ENC_EMB_DIM, mask_zero=True, name='enc_emb')(encoder_inputs)\n",
        "# Note: use_cudnn=False is implicitly handled if not specified, as weights are loaded\n",
        "encoder_lstm = LSTM(ENC_UNITS, return_sequences=True, return_state=True, name='encoder_lstm')\n",
        "enc_outputs, enc_state_h, enc_state_c = encoder_lstm(enc_emb)\n",
        "\n",
        "# Decoder Definition (matching the training model for weight loading)\n",
        "decoder_inputs = Input(shape=(ANS_SEQ_LEN+1,), dtype='int32', name='decoder_inputs')\n",
        "dec_emb_layer = Embedding(input_dim=len(answer_vectorizer.get_vocabulary()), output_dim=DEC_EMB_DIM, mask_zero=True, name='dec_emb')\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# Note: use_cudnn=False is implicitly handled if not specified, as weights are loaded\n",
        "decoder_lstm = LSTM(DEC_UNITS, return_sequences=True, return_state=True, name='decoder_lstm')\n",
        "dec_lstm_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[enc_state_h, enc_state_c])\n",
        "\n",
        "attn = Attention(name='attention_layer')\n",
        "context = attn([dec_lstm_outputs, enc_outputs])\n",
        "concat = Concatenate(axis=-1, name='concat_layer')([context, dec_lstm_outputs])\n",
        "decoder_dense = Dense(len(answer_vectorizer.get_vocabulary()), activation='softmax', name='decoder_dense')\n",
        "decoder_outputs = decoder_dense(concat)\n",
        "\n",
        "# Construct the training model again with named layers to load weights correctly\n",
        "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs, name='training_model')\n",
        "\n",
        "# Load best weights into the rebuilt training model\n",
        "weights_path = os.path.join(SAVE_DIR, 'best_weights.weights.h5') # Fixed: added '.weights' to the filename\n",
        "training_model.load_weights(weights_path)\n",
        "print(\"Loaded weights from\", weights_path)\n",
        "\n",
        "# Build Encoder Model for Inference\n",
        "# This model takes the clue input and outputs the encoder's final states and all hidden states (for attention)\n",
        "encoder_model = Model(encoder_inputs, [enc_outputs, enc_state_h, enc_state_c])\n",
        "\n",
        "# Build One-Step Decoder Model for Inference\n",
        "# This model predicts one character at a time, taking the previously predicted character,\n",
        "# the current decoder states, and the encoder outputs as input.\n",
        "dec_token_input = Input(shape=(1,), dtype='int32', name='dec_token_input') # Input for a single token\n",
        "dec_h_in = Input(shape=(DEC_UNITS,), name='dec_h_in') # Input for previous decoder hidden state\n",
        "dec_c_in = Input(shape=(DEC_UNITS,), name='dec_c_in') # Input for previous decoder cell state\n",
        "enc_outs_in = Input(shape=(CLUE_SEQ_LEN, ENC_UNITS), name='enc_outs_in') # Input for all encoder outputs (for attention)\n",
        "\n",
        "# Reuse layers by name from the training_model to ensure same weights are used\n",
        "dec_emb_layer = training_model.get_layer('dec_emb')\n",
        "decoder_lstm_layer = training_model.get_layer('decoder_lstm')\n",
        "decoder_dense_layer = training_model.get_layer('decoder_dense')\n",
        "attention_layer = training_model.get_layer('attention_layer')\n",
        "\n",
        "# Process single token through decoder embedding, LSTM, and attention\n",
        "dec_emb_step = dec_emb_layer(dec_token_input)  # (batch,1,emb_dim)\n",
        "dec_lstm_out_step, dec_h_out, dec_c_out = decoder_lstm_layer(dec_emb_step, initial_state=[dec_h_in, dec_c_in])  # (batch,1,dec_units)\n",
        "\n",
        "# Apply attention: query=decoder output, value=encoder outputs\n",
        "context_step = attention_layer([dec_lstm_out_step, enc_outs_in])  # (batch,1,enc_units)\n",
        "# Concatenate context vector with decoder LSTM output\n",
        "concat_step = Concatenate(axis=-1)([context_step, dec_lstm_out_step])  # (batch,1,enc+dec)\n",
        "# Predict next token's probability distribution\n",
        "preds_step = decoder_dense_layer(concat_step)  # (batch,1,vocab)\n",
        "\n",
        "# Define the decoder model for inference\n",
        "decoder_model = Model([dec_token_input, dec_h_in, dec_c_in, enc_outs_in],\n",
        "                      [preds_step, dec_h_out, dec_c_out])\n",
        "\n",
        "print(\"Built encoder_model and decoder_model for inference.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sulM8Qntq5OJ",
        "outputId": "8c6de28f-7e64-47f3-f518-4ff6186d5c9a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded weights from /content/drive/MyDrive/crossword_model/best_weights.weights.h5\n",
            "Built encoder_model and decoder_model for inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load vectorizers, need to load these if you're in a new session\n",
        "with open(os.path.join(SAVE_DIR, 'clue_vectorizer.pkl'), 'rb') as f:\n",
        "    clue_vectorizer = pickle.load(f)\n",
        "with open(os.path.join(SAVE_DIR, 'answer_vectorizer.pkl'), 'rb') as f:\n",
        "    answer_vectorizer = pickle.load(f)\n",
        "\n",
        "# Re-initialize token mappings after loading vectorizers\n",
        "idx_to_token = {i: t for i, t in enumerate(answer_vectorizer.get_vocabulary())}\n",
        "token_to_idx = {t: i for i, t in idx_to_token.items()}\n",
        "SOS = token_to_idx['[SOS]']\n",
        "EOS = token_to_idx['[EOS]']\n",
        "UNK = token_to_idx['[UNK]']\n",
        "\n",
        "def encode_clue(clue_text):\n",
        "    \"\"\"\n",
        "    Encodes a single clue text using the encoder_model.\n",
        "    Returns encoder outputs and the final hidden and cell states.\n",
        "    \"\"\"\n",
        "    seq = clue_vectorizer([clue_text])  # shape (1, CLUE_SEQ_LEN)\n",
        "    enc_outs, h, c = encoder_model.predict(seq, verbose=0)\n",
        "    return enc_outs, h, c\n",
        "\n",
        "import math\n",
        "def beam_search(clue_text, beam_width=5, max_len=ANS_SEQ_LEN+1):\n",
        "    \"\"\"\n",
        "    Performs beam search to decode the best possible answer for a given clue.\n",
        "    \"\"\"\n",
        "    # Encode the input clue to get initial encoder states\n",
        "    enc_outs, h, c = encode_clue(clue_text)\n",
        "    # Initialize beams: (log_probability, token_sequence, decoder_h_state, decoder_c_state)\n",
        "    beams = [(0.0, [SOS], h, c)]\n",
        "    completed = [] # Stores completed sequences (ended with EOS)\n",
        "\n",
        "    # Iterate for a maximum sequence length\n",
        "    for _ in range(max_len):\n",
        "        all_candidates = []\n",
        "        for logp, seq, h_state, c_state in beams:\n",
        "            # If the sequence is already completed, add to completed list and continue\n",
        "            last = seq[-1]\n",
        "            if last == EOS:\n",
        "                completed.append((logp, seq))\n",
        "                continue\n",
        "\n",
        "            # Predict the next character distribution using the decoder model\n",
        "            # Input: last predicted token, current decoder states, encoder outputs (for attention)\n",
        "            preds, h_new, c_new = decoder_model.predict([np.array([[last]]), h_state, c_state, enc_outs], verbose=0)\n",
        "            probs = preds[0,0,:]  # Get probabilities for the next token (shape: vocab_size)\n",
        "\n",
        "            # Select top-k (beam_width) indices based on probabilities\n",
        "            top_idxs = np.argpartition(-probs, beam_width)[:beam_width]\n",
        "\n",
        "            # Create new candidates for the next beam\n",
        "            for idx in top_idxs:\n",
        "                p = probs[int(idx)]\n",
        "                if p <= 0: # Avoid log of zero\n",
        "                    continue\n",
        "                # Calculate new log probability and new sequence\n",
        "                cand = (logp + math.log(p + 1e-12), seq + [int(idx)], h_new, c_new)\n",
        "                all_candidates.append(cand)\n",
        "\n",
        "        # If no candidates are generated (e.g., all beams ended with EOS or invalid tokens),\n",
        "        # break the loop\n",
        "        if not all_candidates:\n",
        "            break\n",
        "        # Sort all candidates by log probability and select the top 'beam_width' for the next iteration\n",
        "        all_candidates.sort(key=lambda x: x[0], reverse=True)\n",
        "        beams = all_candidates[:beam_width]\n",
        "\n",
        "    # Combine completed sequences with any remaining active beams\n",
        "    final = completed + [(b[0], b[1]) for b in beams]\n",
        "    # Sort all final sequences by log probability\n",
        "    final.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    results = []\n",
        "    for score, seq in final[:beam_width]:\n",
        "        # Convert token IDs back to characters, stopping at EOS token\n",
        "        toks = seq[1:]  # Drop SOS token\n",
        "        chars = []\n",
        "        for t in toks:\n",
        "            if t == EOS:\n",
        "                break\n",
        "            # Get character from ID, handling unknown tokens\n",
        "            token = idx_to_token.get(int(t), '')\n",
        "            if token in ['[UNK]','[SOS]','[EOS]','[PAD]']:\n",
        "                if token == '[UNK]':\n",
        "                    chars.append('?') # Represent UNK as '?'\n",
        "                continue\n",
        "            chars.append(token)\n",
        "        ans = ''.join(chars)\n",
        "        results.append((score, ans))\n",
        "    return results\n",
        "\n",
        "# Quick test\n",
        "print(beam_search(\"Sense of self\", beam_width=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWbNgcYTq8F2",
        "outputId": "055f63da-2a56-4ff0-c572-924b2f704353"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(-0.49861428113795975, 'EGO'), (-3.2689418383214064, 'HERE'), (-3.6076852292503885, 'HER')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch Demo\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def gr_predict(clue, top_k=5):\n",
        "    if not isinstance(clue, str) or clue.strip() == '':\n",
        "        return \"Please enter a clue.\"\n",
        "    preds = beam_search(clue, beam_width=top_k)\n",
        "    out = []\n",
        "    for score, ans in preds:\n",
        "        out.append(f\"{ans}    (score: {score:.3f})\")\n",
        "    return \"\\n\".join(out)\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=lambda clue, k: gr_predict(clue, top_k=k),\n",
        "    inputs=[gr.Textbox(lines=2, placeholder=\"Enter crossword clue...\"), gr.Slider(1, 10, value=5, step=1, label=\"Top k\")],\n",
        "    outputs=gr.Textbox(label=\"Top-k predictions\"),\n",
        "    title=\"Crossword Clue Answer Generator\",\n",
        "    description=\"Seq2seq LSTM + Attention with beam search (top-k).\"\n",
        ")\n",
        "\n",
        "# Launch\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "b_U1fr07q9vn",
        "outputId": "b3789a34-645e-4f5e-c242-368c8c2d9694"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://78280ac20f3221838e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://78280ac20f3221838e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}